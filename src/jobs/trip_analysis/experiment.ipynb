{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/04 20:37:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"NYC_Taxi_Analysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.parquet(\"NYC/*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['VendorID',\n",
       "  'tpep_pickup_datetime',\n",
       "  'tpep_dropoff_datetime',\n",
       "  'passenger_count',\n",
       "  'trip_distance',\n",
       "  'RatecodeID',\n",
       "  'store_and_fwd_flag',\n",
       "  'PULocationID',\n",
       "  'DOLocationID',\n",
       "  'payment_type',\n",
       "  'fare_amount',\n",
       "  'extra',\n",
       "  'mta_tax',\n",
       "  'tip_amount',\n",
       "  'tolls_amount',\n",
       "  'improvement_surcharge',\n",
       "  'total_amount',\n",
       "  'congestion_surcharge',\n",
       "  'airport_fee'],\n",
       " 19)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns, len(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"NYC_Taxi_Analysis\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file_path = \"./NYC/*.parquet\"\n",
    "taxi_df = spark.read.parquet(parquet_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trip Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Duration and Distance:\n",
    "Create a new column for trip duration and calculate it using the difference between pickup and dropoff times. Also, calculate the average distance for each record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "taxi_df = taxi_df.withColumn(\"trip_duration\", F.unix_timestamp(\"tpep_dropoff_datetime\") - F.unix_timestamp(\"tpep_pickup_datetime\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df = taxi_df.withColumn(\"avg_distance\", (F.col(\"trip_distance\") / F.col(\"passenger_count\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Time of Day, Day of Week, and Month of Year:\n",
    "- Extract the desired time components from the tpep_pickup_datetime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df = taxi_df.withColumn(\"pickup_hour\", F.hour(\"tpep_pickup_datetime\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df = taxi_df.withColumn(\"pickup_day_of_week\", F.dayofweek(\"tpep_pickup_datetime\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df = taxi_df.withColumn(\"pickup_month\", F.month(\"tpep_pickup_datetime\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group and Aggregate:\n",
    "Group the data by time of day, day of week, and month of year, and calculate the average duration and distance for each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = taxi_df.groupBy(\"pickup_hour\", \"pickup_day_of_week\", \"pickup_month\").agg(\n",
    "    F.avg(\"trip_duration\").alias(\"avg_duration\"),\n",
    "    F.avg(\"avg_distance\").alias(\"avg_distance\")\n",
    ").orderBy(\"pickup_hour\", \"pickup_day_of_week\", \"pickup_month\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the Results:\n",
    "Show the aggregated results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+------------+------------------+------------------+\n",
      "|pickup_hour|pickup_day_of_week|pickup_month|      avg_duration|      avg_distance|\n",
      "+-----------+------------------+------------+------------------+------------------+\n",
      "|          0|                 1|           1| 888.9417608770127|3.2521391261294736|\n",
      "|          0|                 1|           2| 726.9726522187823|  2.89541996285979|\n",
      "|          0|                 1|           3| 888.4640534063677|2.8471578638497625|\n",
      "|          0|                 1|           4| 854.6067429406037|2.9782131248083417|\n",
      "|          0|                 1|           5| 883.9497659700705|2.8323654661521616|\n",
      "|          0|                 1|           6| 954.6639178045153| 2.721734596752614|\n",
      "|          0|                 1|           7|1011.6342042755344| 2.835302943232113|\n",
      "|          0|                 1|           8| 997.7019489609131|2.8669667749237213|\n",
      "|          0|                 1|           9|1057.5752172184677|2.5259332031492243|\n",
      "|          0|                 1|          10| 983.6769738118331|2.4983152044322683|\n",
      "|          0|                 1|          11| 935.9346515215258| 2.539192359159652|\n",
      "|          0|                 1|          12| 972.2170118615943| 3.150238748796069|\n",
      "|          0|                 2|           1| 915.7601380500431| 4.946866130558188|\n",
      "|          0|                 2|           2|1105.8451242829829| 4.494771421675113|\n",
      "|          0|                 2|           3|  820.387349953832| 5.216901033850259|\n",
      "|          0|                 2|           4| 960.7860179499291| 5.048313027017737|\n",
      "|          0|                 2|           5| 951.8014098690836| 4.508350586080599|\n",
      "|          0|                 2|           6| 971.4392452830189| 4.867711624592842|\n",
      "|          0|                 2|           7| 990.5213815789474|4.3910269512339335|\n",
      "|          0|                 2|           8|1029.8973904639174| 5.536793713681965|\n",
      "+-----------+------------------+------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "agg_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group and Count Pickup Locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_locations = taxi_df.groupBy(\"PULocationID\").count().orderBy(F.desc(\"count\"))\n",
    "top_pickup_locations = pickup_locations.limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropoff_locations = taxi_df.groupBy(\"DOLocationID\").count().orderBy(F.desc(\"count\"))\n",
    "top_dropoff_locations = dropoff_locations.limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
