{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, hour, dayofweek, month\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/04 23:58:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"TaxiAnalysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    column names: VendorID, tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count, trip_distance, RatecodeID, store_and_fwd_flag, PULocationID, DOLocationID, payment_type, fare_amount, extra, mta_tax, tip_amount, tolls_amount, improvement_surcharge, total_amount, congestion_surcharge, airport_fee\n",
    "    \"\"\"\n",
    "    # Load the NYC taxi data from Parquet files\n",
    "    data_nyc = spark.read.parquet(file_path)\n",
    "\n",
    "    return data_nyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trip_analysis(data):\n",
    "    \"\"\"_summary_\n",
    "    Function Task: Average duration and distance of rides: Compare these metrics by time of day, day of week, \n",
    "    and month of year. This can reveal patterns such as longer trips during rush hours, on \n",
    "    weekends, or during holiday seasons.\n",
    "    \"\"\"\n",
    "    # Average duration and distance of rides by time of day, day of week, and month of year\n",
    "    window = Window.orderBy(\"pickup_datetime\")\n",
    "\n",
    "    trip = data.withColumn(\"hour\", hour(\"pickup_datetime\")) \\\n",
    "        .withColumn(\"day_of_week\", dayofweek(\"pickup_datetime\")) \\\n",
    "        .withColumn(\"month\", month(\"pickup_datetime\"))\n",
    "\n",
    "    avg_duration_by_hour = trip.groupBy(\n",
    "        \"hour\").avg(\"trip_duration_minutes\")\n",
    "    avg_distance_by_hour = trip.groupBy(\"hour\").avg(\"trip_distance\")\n",
    "\n",
    "    avg_duration_by_day = trip.groupBy(\n",
    "        \"day_of_week\").avg(\"trip_duration_minutes\")\n",
    "    avg_distance_by_day = trip.groupBy(\n",
    "        \"day_of_week\").avg(\"trip_distance\")\n",
    "\n",
    "    avg_duration_by_month = trip.groupBy(\n",
    "        \"month\").avg(\"trip_duration_minutes\")\n",
    "    avg_distance_by_month = trip.groupBy(\"month\").avg(\"trip_distance\")\n",
    "\n",
    "    avg_duration_by_hour.show()\n",
    "    avg_distance_by_hour.show()\n",
    "    avg_duration_by_day.show()\n",
    "    avg_distance_by_day.show()\n",
    "    avg_duration_by_month.show()\n",
    "    avg_distance_by_month.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popular_locations(data):\n",
    "    # Identify the top 10 pickup and dropoff locations\n",
    "    top_pickup_locations = data.groupBy(\n",
    "        \"PULocationID\").count().orderBy(col(\"count\").desc()).limit(10)\n",
    "    top_dropoff_locations = data.groupBy(\n",
    "        \"DOLocationID\").count().orderBy(col(\"count\").desc()).limit(10)\n",
    "\n",
    "    top_pickup_locations.show()\n",
    "    top_dropoff_locations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tip_analysis(data):\n",
    "    # Tip percentage by trip\n",
    "    data = data.withColumn(\"tip_percentage\", col(\n",
    "        \"tip_amount\") / col(\"total_amount\") * 100)\n",
    "\n",
    "    # Tips by time: Does the time of day, week, or year affect tipping behavior?\n",
    "    tip_by_hour = data.groupBy(hour(\"pickup_datetime\")).avg(\n",
    "        \"tip_percentage\").orderBy(\"hour\")\n",
    "    tip_by_day_of_week = data.groupBy(dayofweek(\"pickup_datetime\")).avg(\n",
    "        \"tip_percentage\").orderBy(\"dayofweek\")\n",
    "    tip_by_month = data.groupBy(month(\"pickup_datetime\")).avg(\n",
    "        \"tip_percentage\").orderBy(\"month\")\n",
    "\n",
    "    tip_by_hour.show()\n",
    "    tip_by_day_of_week.show()\n",
    "    tip_by_month.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fare_analysis(data):\n",
    "    # Can you calculate the average fare by pickup & drop-off location?\n",
    "    avg_fare_by_pickup_dropoff = data.groupBy(\n",
    "        \"PULocationID\", \"DOLocationID\").avg(\"fare_amount\")\n",
    "    avg_fare_by_pickup_dropoff.show()\n",
    "\n",
    "    # Can you calculate the average fare by Passenger count?\n",
    "    avg_fare_by_passenger_count = data.groupBy(\n",
    "        \"passenger_count\").avg(\"fare_amount\")\n",
    "    avg_fare_by_passenger_count.show()\n",
    "\n",
    "    # Can you correlate the fare amount and the distance trip?\n",
    "    data = data.withColumn(\"fare_per_distance\", col(\n",
    "        \"fare_amount\") / col(\"trip_distance\"))\n",
    "\n",
    "    correlation_fare_distance = data.stat.corr(\n",
    "        \"fare_per_distance\", \"trip_distance\")\n",
    "    print(\"Correlation between fare and trip distance:\", correlation_fare_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traffic_analysis(data):\n",
    "    # Calculate the average speed of a trip (average trip speed in miles per hour)\n",
    "    data = data.withColumn(\"trip_speed\", col(\n",
    "        \"trip_distance\") / (col(\"trip_duration_minutes\") / 60))\n",
    "\n",
    "    # Group the average speed by trip then hour, day, week\n",
    "    avg_speed_by_hour = data.groupBy(\n",
    "        hour(\"pickup_datetime\")).avg(\"trip_speed\").orderBy(\"hour\")\n",
    "    avg_speed_by_day_of_week = data.groupBy(\n",
    "        dayofweek(\"pickup_datetime\")).avg(\"trip_speed\").orderBy(\"dayofweek\")\n",
    "    avg_speed_by_month = data.groupBy(\n",
    "        month(\"pickup_datetime\")).avg(\"trip_speed\").orderBy(\"month\")\n",
    "\n",
    "    avg_speed_by_hour.show()\n",
    "    avg_speed_by_day_of_week.show()\n",
    "    avg_speed_by_month.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demand_prediction(data):\n",
    "    # Feature engineering: Use the date and time of the pickups to create features for the model\n",
    "    data = data.withColumn(\"hour_of_day\", hour(\"pickup_datetime\"))\n",
    "    data = data.withColumn(\"day_of_week\", dayofweek(\"pickup_datetime\"))\n",
    "    data = data.withColumn(\"month\", month(\"pickup_datetime\"))\n",
    "\n",
    "    # Regression model: Use linear regression to predict the number of pickups in the next hour\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=[\"hour_of_day\", \"day_of_week\", \"month\"], outputCol=\"features\")\n",
    "    data = assembler.transform(data)\n",
    "\n",
    "    lr = LinearRegression(featuresCol=\"features\",\n",
    "                          labelCol=\"pickups_in_next_hour\")\n",
    "    lr_model = lr.fit(data)\n",
    "\n",
    "    # Make predictions for the next hour based on the features\n",
    "    next_hour_data = spark.createDataFrame(\n",
    "        [(18, 2, 7)], [\"hour_of_day\", \"day_of_week\", \"month\"])\n",
    "    next_hour_data = assembler.transform(next_hour_data)\n",
    "    predictions = lr_model.transform(next_hour_data)\n",
    "\n",
    "    predicted_pickups = predictions.select(\"prediction\").first()[0]\n",
    "    print(\"Predicted number of pickups in the next hour:\", predicted_pickups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "# change this with your google cloud storage path\n",
    "path = os.path.join(cwd, 'NYC', '*.parquet')\n",
    "data_df = load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `pickup_datetime` cannot be resolved. Did you mean one of the following? [`tpep_pickup_datetime`, `tpep_dropoff_datetime`, `airport_fee`, `payment_type`, `tip_amount`].;\n'Project [VendorID#0L, tpep_pickup_datetime#1, tpep_dropoff_datetime#2, passenger_count#3, trip_distance#4, RatecodeID#5, store_and_fwd_flag#6, PULocationID#7L, DOLocationID#8L, payment_type#9L, fare_amount#10, extra#11, mta_tax#12, tip_amount#13, tolls_amount#14, improvement_surcharge#15, total_amount#16, congestion_surcharge#17, airport_fee#18, hour('pickup_datetime, Some(Europe/Paris)) AS hour#38]\n+- Relation [VendorID#0L,tpep_pickup_datetime#1,tpep_dropoff_datetime#2,passenger_count#3,trip_distance#4,RatecodeID#5,store_and_fwd_flag#6,PULocationID#7L,DOLocationID#8L,payment_type#9L,fare_amount#10,extra#11,mta_tax#12,tip_amount#13,tolls_amount#14,improvement_surcharge#15,total_amount#16,congestion_surcharge#17,airport_fee#18] parquet\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trip_analysis(data_df)\n",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m, in \u001b[0;36mtrip_analysis\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39m# Average duration and distance of rides by time of day, day of week, and month of year\u001b[39;00m\n\u001b[1;32m      8\u001b[0m window \u001b[39m=\u001b[39m Window\u001b[39m.\u001b[39morderBy(\u001b[39m\"\u001b[39m\u001b[39mpickup_datetime\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m trip \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mwithColumn(\u001b[39m\"\u001b[39;49m\u001b[39mhour\u001b[39;49m\u001b[39m\"\u001b[39;49m, hour(\u001b[39m\"\u001b[39;49m\u001b[39mpickup_datetime\u001b[39;49m\u001b[39m\"\u001b[39;49m)) \\\n\u001b[1;32m     11\u001b[0m     \u001b[39m.\u001b[39mwithColumn(\u001b[39m\"\u001b[39m\u001b[39mday_of_week\u001b[39m\u001b[39m\"\u001b[39m, dayofweek(\u001b[39m\"\u001b[39m\u001b[39mpickup_datetime\u001b[39m\u001b[39m\"\u001b[39m)) \\\n\u001b[1;32m     12\u001b[0m     \u001b[39m.\u001b[39mwithColumn(\u001b[39m\"\u001b[39m\u001b[39mmonth\u001b[39m\u001b[39m\"\u001b[39m, month(\u001b[39m\"\u001b[39m\u001b[39mpickup_datetime\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     14\u001b[0m avg_duration_by_hour \u001b[39m=\u001b[39m trip\u001b[39m.\u001b[39mgroupBy(\n\u001b[1;32m     15\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mhour\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mavg(\u001b[39m\"\u001b[39m\u001b[39mtrip_duration_minutes\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m avg_distance_by_hour \u001b[39m=\u001b[39m trip\u001b[39m.\u001b[39mgroupBy(\u001b[39m\"\u001b[39m\u001b[39mhour\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mavg(\u001b[39m\"\u001b[39m\u001b[39mtrip_distance\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dsp/lib/python3.9/site-packages/pyspark/sql/dataframe.py:4789\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   4784\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(col, Column):\n\u001b[1;32m   4785\u001b[0m     \u001b[39mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m   4786\u001b[0m         error_class\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNOT_COLUMN\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   4787\u001b[0m         message_parameters\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39marg_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mcol\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39marg_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(col)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m   4788\u001b[0m     )\n\u001b[0;32m-> 4789\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrame(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mwithColumn(colName, col\u001b[39m.\u001b[39;49m_jc), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/miniconda3/envs/dsp/lib/python3.9/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/dsp/lib/python3.9/site-packages/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `pickup_datetime` cannot be resolved. Did you mean one of the following? [`tpep_pickup_datetime`, `tpep_dropoff_datetime`, `airport_fee`, `payment_type`, `tip_amount`].;\n'Project [VendorID#0L, tpep_pickup_datetime#1, tpep_dropoff_datetime#2, passenger_count#3, trip_distance#4, RatecodeID#5, store_and_fwd_flag#6, PULocationID#7L, DOLocationID#8L, payment_type#9L, fare_amount#10, extra#11, mta_tax#12, tip_amount#13, tolls_amount#14, improvement_surcharge#15, total_amount#16, congestion_surcharge#17, airport_fee#18, hour('pickup_datetime, Some(Europe/Paris)) AS hour#38]\n+- Relation [VendorID#0L,tpep_pickup_datetime#1,tpep_dropoff_datetime#2,passenger_count#3,trip_distance#4,RatecodeID#5,store_and_fwd_flag#6,PULocationID#7L,DOLocationID#8L,payment_type#9L,fare_amount#10,extra#11,mta_tax#12,tip_amount#13,tolls_amount#14,improvement_surcharge#15,total_amount#16,congestion_surcharge#17,airport_fee#18] parquet\n"
     ]
    }
   ],
   "source": [
    "trip_analysis(data_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
