{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, hour, dayofweek, month\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/05 11:18:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"TaxiAnalysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    column names: VendorID, tpep_pickup_datetime, tpep_dropoff_datetime,\n",
    "    passenger_count, trip_distance, RatecodeID, store_and_fwd_flag,\n",
    "    PULocationID, DOLocationID, payment_type, fare_amount, extra, mta_tax,\n",
    "    tip_amount, tolls_amount, improvement_surcharge, total_amount,\n",
    "    congestion_surcharge, airport_fee\n",
    "    \"\"\"\n",
    "    # Load the NYC taxi data from Parquet files\n",
    "    data_nyc = spark.read.parquet(path)\n",
    "\n",
    "    return data_nyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trip_analysis(data):\n",
    "    \"\"\"_summary_\n",
    "    Function Task: Average duration and distance of rides: Compare these metrics by time of day, day of week, \n",
    "    and month of year. This can reveal patterns such as longer trips during rush hours, on \n",
    "    weekends, or during holiday seasons.\n",
    "    \"\"\"\n",
    "    # Average duration and distance of rides by time of day, day of week, and month of year\n",
    "    data = data.withColumn(\"trip_duration_minutes\",\n",
    "                           F.unix_timestamp(\"tpep_dropoff_datetime\") - F.unix_timestamp(\"tpep_pickup_datetime\"))\n",
    "\n",
    "    data = data.withColumn(\"avg_distance\", (F.col(\"trip_distance\") / F.col(\"passenger_count\")))\n",
    "    data = data.withColumn(\"pickup_hour\", F.hour(\"tpep_pickup_datetime\"))\n",
    "    data = data.withColumn(\"pickup_day_of_week\", F.dayofweek(\"tpep_pickup_datetime\"))\n",
    "    data = data.withColumn(\"pickup_month\", F.month(\"tpep_pickup_datetime\"))\n",
    "\n",
    "    agg_df = data.groupBy(\"pickup_hour\", \"pickup_day_of_week\", \"pickup_month\").agg(F.avg(\"trip_duration\").alias(\"avg_duration\"), F.avg(\"avg_distance\").alias(\"avg_distance\")).orderBy(\"pickup_hour\", \"pickup_day_of_week\", \"pickup_month\")\n",
    "    \n",
    "\n",
    "    pickup_locations = data.groupBy(\n",
    "        \"PULocationID\").count().orderBy(F.desc(\"count\"))\n",
    "    top_pickup_locations = pickup_locations.limit(10)\n",
    "\n",
    "    dropoff_locations = data.groupBy(\n",
    "        \"DOLocationID\").count().orderBy(F.desc(\"count\"))\n",
    "    top_dropoff_locations = dropoff_locations.limit(10)\n",
    "\n",
    "    return agg_df, top_pickup_locations, top_dropoff_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tip_analysis(data):\n",
    "\n",
    "    tip_analysis_df = data.withColumn(\"tip_percentage\", F.col(\n",
    "        \"tip_amount\") / F.col(\"total_amount\") * 100)\n",
    "    tip_analysis_df = tip_analysis_df.withColumn(\"tip_percentage\", F.when(F.col(\n",
    "        \"tip_percentage\") <= 100, F.col(\"tip_percentage\")).otherwise(0))  # Handle possible outliers\n",
    "\n",
    "    # Group by pickup and dropoff locations and calculate average tip percentage and average distance\n",
    "    tip_location_analysis = tip_analysis_df.groupBy(\n",
    "        \"PULocationID\",\n",
    "        \"DOLocationID\"\n",
    "    ).agg(\n",
    "        F.avg(\"tip_percentage\").alias(\"avg_tip_percentage\"),\n",
    "        F.avg(\"trip_distance\").alias(\"avg_distance\")\n",
    "    ).orderBy(F.desc(\"avg_tip_percentage\"))\n",
    "\n",
    "    tip_time_analysis = tip_analysis_df.groupBy(\n",
    "        \"pickup_hour\",\n",
    "        \"pickup_day_of_week\",\n",
    "        \"pickup_month\"\n",
    "    ).agg(\n",
    "        F.avg(\"tip_percentage\").alias(\"avg_tip_percentage\"),\n",
    "        F.sum(\"tip_amount\").alias(\"total_tip_amount\")\n",
    "    ).orderBy(\n",
    "        \"pickup_hour\",\n",
    "        \"pickup_day_of_week\",\n",
    "        \"pickup_month\")\n",
    "\n",
    "    payment_tip_analysis = tip_analysis_df.groupBy(\"payment_type\").agg(F.avg(\"tip_percentage\").alias(\"avg_tip_percentage\"),\n",
    "                                                                       F.avg(\"tip_amount\").alias(\n",
    "                                                                           \"avg_tip_amount\"),\n",
    "                                                                       F.sum(\"tip_amount\").alias(\"total_tip_amount\"))\n",
    "\n",
    "    return tip_location_analysis, tip_time_analysis, payment_tip_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fare_analysis(data):\n",
    "    fare_location_analysis = data.groupBy(\"PULocationID\", \"DOLocationID\").\\\n",
    "        agg(F.avg(\"fare_amount\").alias(\"avg_fare\")).\\\n",
    "        orderBy(F.desc(\"avg_fare\"))\n",
    "\n",
    "    fare_passenger_analysis = data.groupBy(\"passenger_count\").\\\n",
    "        agg(F.avg(\"fare_amount\").alias(\"avg_fare\")).\\\n",
    "        orderBy(\"passenger_count\")\n",
    "    fare_distance_correlation = data.select(F.corr(\"fare_amount\", \"trip_distance\").\n",
    "                                            alias(\"correlation\")).\\\n",
    "        collect()[0][\"correlation\"]\n",
    "\n",
    "    return fare_location_analysis, fare_passenger_analysis, fare_distance_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traffic_analysis(data):\n",
    "    trip_speed_df = data.withColumn(\"trip_speed\", (F.col(\n",
    "        \"trip_distance\") / (F.col(\"trip_duration\") / 3600)))\n",
    "\n",
    "    trip_time_speed_analysis = trip_speed_df.groupBy(\"PULocationID\",\n",
    "                                                     \"DOLocationID\",\n",
    "                                                     \"pickup_hour\",\n",
    "                                                     \"pickup_day_of_week\",\n",
    "                                                     \"pickup_month\").\\\n",
    "        agg(F.avg(\"trip_speed\").\n",
    "            alias(\"avg_trip_speed\")).\\\n",
    "        orderBy(\"PULocationID\",\n",
    "                \"DOLocationID\",\n",
    "                \"pickup_hour\",\n",
    "                \"pickup_day_of_week\",\n",
    "                \"pickup_month\")\n",
    "    return trip_time_speed_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demand_prediction(data):\n",
    "\n",
    "    demand_df = data.withColumn(\"pickup_hour\", F.hour(\"tpep_pickup_datetime\"))\n",
    "    demand_df = demand_df.withColumn(\n",
    "        \"pickup_day_of_week\", F.dayofweek(\"tpep_pickup_datetime\"))\n",
    "    demand_df = demand_df.withColumn(\n",
    "        \"pickup_month\", F.month(\"tpep_pickup_datetime\"))\n",
    "\n",
    "    feature_columns = [\"pickup_hour\", \"pickup_day_of_week\", \"pickup_month\"]\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=feature_columns, outputCol=\"features\")\n",
    "    demand_df = assembler.transform(demand_df)\n",
    "\n",
    "    feature_columns = [\"pickup_hour\", \"pickup_day_of_week\", \"pickup_month\"]\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=feature_columns, outputCol=\"input_features\")\n",
    "    demand_df = assembler.transform(demand_df)\n",
    "\n",
    "    # Aggregate data for regression\n",
    "    regression_df = demand_df.groupBy(\"pickup_hour\").agg(\n",
    "        F.sum(\"passenger_count\").alias(\"total_pickups\"),\n",
    "        F.first(\"input_features\").alias(\"features\"))\n",
    "\n",
    "    lr = LinearRegression(featuresCol=\"features\", labelCol=\"total_pickups\")\n",
    "    lr_model = lr.fit(regression_df)\n",
    "\n",
    "    return lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./NYC/*.parquet\"\n",
    "data = load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip = trip_analysis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip = tip_analysis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare = fare_analysis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = traffic_analysis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_model = demand_prediction(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip[0].show()\n",
    "print(\"Top 10 Pickup Locations:\")\n",
    "trip[1].show()\n",
    "print(\"Top 10 Dropoff Locations:\")\n",
    "trip[2].show()\n",
    "print(\"Tip Analysis by Location:\")\n",
    "tip[0].show()\n",
    "print(\"Tip Analysis by Time:\")\n",
    "tip[1].show()\n",
    "print(\"Payment and Tip Analysis:\")\n",
    "tip[2].show()\n",
    "print(\"Average Fare by Pickup & Drop Location:\")\n",
    "fare[0].show()\n",
    "print(\"Average Fare by Passenger Count:\")\n",
    "fare[1].show()\n",
    "print(\"Correlation between Fare Amount and Trip Distance:\")\n",
    "print(\"Correlation coefficient:\", fare[2])\n",
    "traffic.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
